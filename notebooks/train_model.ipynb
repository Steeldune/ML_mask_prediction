{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Model Training\n",
    "====================\n",
    "\n",
    "First we import all the functions. This Notebook will allow us to grab files for the training of a new model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports succesful!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from shutil import copy\n",
    "\n",
    "import mask_prediction.unet_semantics as model_setup\n",
    "import mask_prediction.data_retrievals as data\n",
    "import mask_prediction.apply_weights as weights\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "print('Imports succesful!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "________________\n",
    "Initialising\n",
    "---------\n",
    "- First the train and test model folders are set up.\n",
    "- We're setting up the environment, and initialise some file names.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "##### GPU setup #####\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"    #chose which GPU to use (0-3)\n",
    "\n",
    "##### CPU setup #####\n",
    "os.environ['MKL_NUM_THREADS'] = '20'     #chose the amount of CPUs to use, idk if this is working right now?\n",
    "os.environ['GOTO_NUM_THREADS'] = '20'    #however, maybe works if GPU is not present/working\n",
    "os.environ['OMP_NUM_THREADS'] = '20'\n",
    "os.environ['openmp'] = 'True'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training parameters\n",
    "--\n",
    "The model can be trained both on manually annotated masks, and partially annotated masks, based on a paper by Qu et. al.\n",
    "Another option is to use secondary data in the training set or not. By default this will look up the Hoechst data in the datasets.\n",
    "Preprocessing on the input data can also be done, by normalizing or even thresholding this secondary dataset.\n",
    "\n",
    "To initialize the training set, a percentage of the training data can also be used to populate the testing folders."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "##### General variables #####\n",
    "IMG_SIZE = 1024     #size in pixels of 1 EM tile\n",
    "BATCH_SIZE = 4          #How many images to take in at once on the GPU.\n",
    "\n",
    "##### Parameters of this particular run #####\n",
    "model_name = 'qu_base_em_predho'\n",
    "ini_data_path = 'X:\\\\BEP_data\\\\'#File containing data structure\n",
    "Ho_adjust = False               #Threshold the Hoechst for the purpose of amplification.\n",
    "normalize = True                #Whether to normalize the secondary data coming in\n",
    "using_weights = True           #Whether weights are used within the mask data\n",
    "TRAIN_WITH_FM = True            #Use the FM data when training. Creates model with either 3 (True) or 1 (False) input channels.\n",
    "PATIENCE = 50                   #How many epochs with no discernable difference in loss to wait before prematurely terminating training.\n",
    "TRAIN_TEST_SPLIT = .8           #What percentage of available mask images will be used as training data. The inverse will be used as validation data.\n",
    "\n",
    "##### Folders that will be used in this run #####\n",
    "\n",
    "mask_folder = 'X:\\\\BEP_data\\\\RL012\\\\Manual Masks'       #Folder containing manually annotated masks\n",
    "train_folder = 'X:\\\\BEP_data\\\\Train_set\\\\Train_masks\\\\1'#Folder from which the model will collect training images\n",
    "test_folder = 'X:\\\\BEP_data\\\\Test_set\\\\Test_masks\\\\1'   #Folder from which the model will collect validation images\n",
    "partial_annotation_folder = 'X:\\\\BEP_data\\\\Partial Annotation\\\\temp'\n",
    "mask_list =  glob(mask_folder + '\\\\*.png')              #Glob string filtering which masks to take."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 28 images\n",
      "Testing on 7 images\n"
     ]
    }
   ],
   "source": [
    "def choice(str_list, percent):\n",
    "    random.shuffle(str_list)\n",
    "    cut = int(len(str_list) * percent)\n",
    "    return str_list[:cut], str_list[cut:]\n",
    "\n",
    "if using_weights:\n",
    "    ITERATION_COUNT = 4     #How many partial annotation iterations to go over before calling the model done.\n",
    "    size_filter = 5e5       #area in pixels which has to cover the weights image for it to be used in training. (pixel values range from 0 to 255)\n",
    "    pnt_ratio = .8          #ratio of blobs which will be used in the final image.\n",
    "\n",
    "    radius_array = weights.get_radius_sample('X:\\\\BEP_data\\\\Train_set\\\\blobs\\\\1\\\\')\n",
    "    mean_diam = np.mean(radius_array, dtype=int)\n",
    "\n",
    "    point_mask_list = weights.convert_partial_annotation(mask_folder, partial_annotation_folder, mean_diam, IMG_SIZE=IMG_SIZE, pnt_ratio=pnt_ratio)\n",
    "\n",
    "\n",
    "train_list, test_list = choice((mask_list, point_mask_list)[using_weights], TRAIN_TEST_SPLIT)\n",
    "\n",
    "for image_name in glob(train_folder + '\\\\*.png'):\n",
    "    os.remove(image_name)\n",
    "for image_name in glob(test_folder + '\\\\*.png'):\n",
    "    os.remove(image_name)\n",
    "\n",
    "for train in train_list:\n",
    "    copy(train, train_folder)\n",
    "for test in test_list:\n",
    "    copy(test, test_folder)\n",
    "\n",
    "print('Training on {} images'.format(len(train_list)))\n",
    "print('Testing on {} images'.format(len(test_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next the model is trained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_export = 'X:\\\\BEP_Project\\\\Models\\\\{}'.format(model_name)\n",
    "IMG_CHANNELS = (1,3)[TRAIN_WITH_FM]\n",
    "\n",
    "\n",
    "model_setup.Train_Model(ini_data_path, model_export, IMG_WIDTH=IMG_SIZE, IMG_HEIGHT=IMG_SIZE, IMG_CHANNELS= IMG_CHANNELS,\n",
    "                        BATCH_SIZE=BATCH_SIZE, patience=PATIENCE, normalize=normalize, using_weights=using_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}